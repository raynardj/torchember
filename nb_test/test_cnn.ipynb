{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A full example\n",
    "> A more detailed example on how we use torchember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read this notebook in 30 sec\n",
    "* Even though this is a tiny walk through version, most of the code has nothing to do with torchember\n",
    "* The lines of codes that's relate to the ```torchember``` are marked with \n",
    "```python\n",
    "# ========= TORCHEMBER CODE ===========\n",
    "```\n",
    "\n",
    "### Scope of this notebook\n",
    "* Most of the codes in this notebook has nothing to do with torchember\n",
    "* The training framework is optional, you can use fast.ai, catalyst or forgebox or you just write the iteration all by yourself\n",
    "\n",
    "### Possible extra dependency beside anaconda\n",
    "* pytorch: ... that goes without saying\n",
    "* torchvision: ```pip install torchvision```\n",
    "* forgebox: ```pip install forgebox```\n",
    "* torchember: ```pip install torchember```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import torchvision.transforms as tfm\n",
    "from forgebox.ftorch.train import Trainer\n",
    "from forgebox.ftorch.prepro import test_DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pytorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image trainsformtion funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = tfm.Compose([\n",
    "    tfm.ToTensor(),\n",
    "    tfm.Normalize(mean = [.5,],std = [.5,]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME  = Path(os.environ['HOME'])\n",
    "DATA = HOME/\"data\"\n",
    "DATA.mkdir(exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = DATA/\"mnist.train\"\n",
    "valid_path = DATA/\"mnist.valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MNIST(train_path,train=True, \n",
    "                  download=False if (train_path/\"MNIST\").exists() else True,\n",
    "                  transform=transforms)\n",
    "valid_set = MNIST(valid_path,train=False, \n",
    "                  download=False if (valid_path/\"MNIST\").exists() else True,\n",
    "                  transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the shape of example x,y, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 28, 28]), torch.Size([1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = test_DS(train_set)()\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(in_, out_,ks=3,bias=True):\n",
    "    return nn.Conv2d(in_,out_, kernel_size=ks, padding=ks//2,bias = bias)\n",
    "\n",
    "class vggBlock(nn.Module):\n",
    "    def __init__(self, in_,out_,nb_layers):\n",
    "        super().__init__()\n",
    "        self.in_ = in_\n",
    "        self.out_ = out_\n",
    "        self.nb_layers = nb_layers\n",
    "        self.seq = nn.Sequential(*self.create_convs())\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.seq(x)\n",
    "        \n",
    "    def create_convs(self,):\n",
    "        layers = []\n",
    "        for l in range(self.nb_layers):\n",
    "            if l == 0 : layers.append(conv2d(self.in_,self.out_))\n",
    "            else:layers.append(conv2d(self.out_,self.out_))\n",
    "                \n",
    "            layers.append(nn.BatchNorm2d(self.out_))\n",
    "            layers.append(nn.LeakyReLU())\n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "        return layers\n",
    "\n",
    "class tinyVGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(*[\n",
    "            vggBlock(1,16,2),\n",
    "            vggBlock(16,32,2),\n",
    "            vggBlock(32,64,2),\n",
    "        ])\n",
    "        self.fcb = nn.Sequential(*[\n",
    "            nn.Linear(64*3*3, 256,bias = True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,10),\n",
    "            nn.BatchNorm1d(10),\n",
    "        ])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        bs = x.size(0)\n",
    "        x = self.features(x).view(bs,-1)\n",
    "        x = self.fcb(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arm the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mstart analyzing model\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model =tinyVGG()\n",
    "from torchember.core import torchEmber # ========= TORCHEMBER CODE ===========\n",
    "te = torchEmber(model) # ========= TORCHEMBER CODE ==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Notice, The Trainer was not initiated with optimizer\n",
      "            Use the following syntax to initialize optimizer\n",
      "            t.opt[\"adm1\"] = torch.optim.Adam(m1.parameters())\n",
      "            t.opt[\"adg1\"] = torch.optim.Adagrad(m2.parameters())\n",
      "============================================================\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "train = Trainer(train_set,val_dataset=valid_set,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.opt[\"adm\"] = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess(x):\n",
    "    return torch.max(x,-1).indices\n",
    "def accuracy(y_,y):\n",
    "    return (guess(y_)==y).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and validation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@train.step_train\n",
    "def action(batch):\n",
    "    if batch.i ==0:\n",
    "        te.mark(phase = \"train\") # ========= TORCHEMBER CODE =========== (optional)\n",
    "        te.mark(epoch = batch.epoch) # ========= TORCHEMBER CODE =========== (optional)\n",
    "    batch.opt.zero_all()\n",
    "    x,y = batch.data\n",
    "    y_ = model(x)\n",
    "    loss = loss_func(y_,y)\n",
    "    acc = accuracy(y_,y)\n",
    "    loss.backward()\n",
    "    batch.opt.step_all()\n",
    "    te.log_model()  # ========= TORCHEMBER CODE =========== (optional)\n",
    "    return {\"loss\":loss.item(),\"acc\":acc.item()}\n",
    "\n",
    "@train.step_val\n",
    "def val_action(batch):\n",
    "    if batch.i ==0:\n",
    "        te.mark(phase = \"valid\") # ========= TORCHEMBER CODE =========== (optional)\n",
    "        te.mark(epoch = batch.epoch) # ========= TORCHEMBER CODE =========== (optional)\n",
    "    x,y = batch.data\n",
    "    y_ = model(x)\n",
    "    loss = loss_func(y_)\n",
    "    acc = accuracy(y_,y)\n",
    "    return {\"loss\":loss.item(),\"acc\":acc.item()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
