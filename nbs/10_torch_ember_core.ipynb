{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 Torch Ember Core\n",
    "> Analyzing How Model Improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use AlexNet as example, \n",
    "We can load AlexNet from ```torchvision```\n",
    "\n",
    "By:\n",
    "* Xiaochen Zhang\n",
    "* Lai Wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.alexnet import AlexNet\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data\n",
    "Create a sample data, something like 2 normalized images in a batch, size 224,224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = (torch.rand(2,3,224,224)-1)*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Ember Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The essence of torch ember, is to place trackers within modules.\n",
    "\n",
    "It will decorate the ```forward``` function to achieve following purpose\n",
    "\n",
    "* What variables come in/out of the module\n",
    "* The happening sequence, containing relationships between sub-modules\n",
    "* The statistics we want for further analysis, eg.\n",
    "    * Min, Max, Mean, Std, of input / outpout tensors\n",
    "    * Min, Max, Mean, Std, of model weights at this iteration\n",
    "    * Min, Max, Mean, Std, of model weights grad at this iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from types import MethodType\n",
    "from datetime import datetime\n",
    "from torchember.helper import color,emberTracker\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "class moduleTrack(object):\n",
    "    def __init__(self,module, name=None, root_module = False):\n",
    "        self.module = module\n",
    "        module.module_tracker = self\n",
    "        \n",
    "        self.base_module = True if len(list(module.modules()))==1 else False\n",
    "        self.root_module = root_module\n",
    "        \n",
    "        self.name = name if name else module.__class__.__name__  \n",
    "        #self.name = f'{name}_tracker' if name else f'{module.__class__.__name__}_tracker'\n",
    "        self.id = id(module)\n",
    "        self.children = []\n",
    "        \n",
    "    def __repr__(self):\n",
    "        rt = f\"<{self.name} @ {hex(self.id)}>\"\n",
    "        if hasattr(self,\"input_dt\"):\n",
    "            rt+=f'\\n\\t[Inputs]{\",\".join(list(k+\" \"+str(list(v.shape)) for k,v in self.input_dt.items()))}'\n",
    "        if hasattr(self,\"output_dt\"):\n",
    "            rt+=f'\\n\\t[Outputs]{\",\".join(list(str(list(v.shape)) for v in self.output_dt))}'\n",
    "        return rt\n",
    "\n",
    "def get_stats(tensor):\n",
    "    \"\"\"\n",
    "    The default statistic method, it will capture\n",
    "    shape of the tensor\n",
    "    mean, std, max, min of the tensor\n",
    "    this will return a dictionary\n",
    "    \"\"\"\n",
    "    def list_prod(l):\n",
    "        result=1\n",
    "        for i in l:\n",
    "            result*=i\n",
    "        return result\n",
    "    return {\"shape\":list(tensor.shape),\n",
    "            \"mean\":tensor.float().mean().item(), \n",
    "            \"std\":tensor.float().std().item(), \n",
    "            \"max\":tensor.float().max().item(), \n",
    "            \"min\":tensor.float().min().item(),\n",
    "            \"cnt_zero\": ((tensor>-1e-10) & (tensor < 1e-10)).sum().item(),\n",
    "            \"zero_pct\": float(((tensor>-1e-10) & (tensor < 1e-10)).sum().item())/list_prod(tensor.shape)}\n",
    "\n",
    "\n",
    "    \n",
    "class torchEmber(object):\n",
    "    def __init__(self, model, verbose = True):\n",
    "        color.green|\"start analyzing model\"\n",
    "        self.modules = dict()\n",
    "        self.verbose = verbose\n",
    "        self.model = model\n",
    "        \n",
    "        if hasattr(model,\"disarm\"):\n",
    "            model.disarm()\n",
    "        \n",
    "        self.model_name = self.model.__class__.__name__\n",
    "        \n",
    "        fname = f\"{self.model_name}_{self.ts_str}\"\n",
    "        self.fname = fname\n",
    "        \n",
    "        self.t = emberTracker(fname)\n",
    "        self.current_mt = None\n",
    "        self.mt_log = []\n",
    "        self.record_extra = False\n",
    "        \n",
    "        self.arm()\n",
    "        \n",
    "        self.legit_ttypes = [\"in\",\"out\",\"weight\"]\n",
    "        for ttype in self.legit_ttypes: self.set_metric(ttype)(get_stats)\n",
    "\n",
    "        if self.verbose: \n",
    "            color.green|f\"[INFO][{self.ts_str}]Creating meta data\"\n",
    "        self.t[f\"base_{fname}\"]={\"start\":self.t.ts, \n",
    "                                 \"user\":os.environ[\"USER\"]}\n",
    "        self.t[f\"vis_{fname}\"] = {\"vis_type\":\"standard\"}\n",
    "        self.t[f\"structure_{fname}\"] = self.mod_tree()\n",
    "        \n",
    "    def mark(self,**kwargs):\n",
    "        self.t.mark(**kwargs)\n",
    "        \n",
    "    def parse_module(self,model, name, root_module = False):\n",
    "        name = f\"{name}({model.__class__.__name__})\"\n",
    "        mt = moduleTrack(model, name, root_module)\n",
    "        self.modules[name]= mt\n",
    "        model.forward = self.module_register(name,model)\n",
    "        \n",
    "        for cname,children in model.named_children():\n",
    "            children_mt = self.parse_module(children,f\"{name}.{cname}\" )\n",
    "            children_mt.parent = mt\n",
    "            mt.children.append(children_mt)\n",
    "        return mt\n",
    "    \n",
    "    def mod_tree(self):\n",
    "        \"\"\"\n",
    "        Return the tree of module\n",
    "        \"\"\"\n",
    "        return self.mod_tree_parse(self.model.module_tracker)\n",
    "        \n",
    "    def mod_tree_parse(self,mt):\n",
    "        rt = {\"name\":mt.name, \"short\":mt.name.split(\".\")[-1]}\n",
    "        if len(mt.children)>0:\n",
    "            rt.update({\"children\":list(self.mod_tree_parse(i) for i in mt.children)})\n",
    "        return rt\n",
    "                \n",
    "        \n",
    "    @property\n",
    "    def ts_str(self):\n",
    "        return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    @property\n",
    "    def ts(self):\n",
    "        return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "    def arm(self):\n",
    "        \"\"\"\n",
    "        arming the tracing function to self.model\n",
    "        \"\"\"\n",
    "        if self.verbose: \n",
    "            color.yellow|f\"[ARMING][START]{self.ts}\"\n",
    "        self.parse_module(self.model,\"model\", root_module = True)\n",
    "        if self.verbose: \n",
    "            color.yellow|f\"[ARMING][SUCCESS]{self.ts}\"\n",
    "            \n",
    "    def disarm(self):\n",
    "        \"\"\"remove the tracing function\"\"\"\n",
    "        for m in self.modules.values():\n",
    "            if self.verbose: \n",
    "                color.blue|f\"[DISARM][{m.name}]{self.ts}\"\n",
    "            self.recover(m)\n",
    "        color.blue|f\"[DISARM][DONE]{self.ts}\"\n",
    "            \n",
    "    def recover(self, m):\n",
    "        if hasattr(m.module.forward,\"former\"):\n",
    "            m.module.forward = m.module.forward.former\n",
    "            \n",
    "    def rearm(self):\n",
    "        self.disarm()\n",
    "        self.arm()\n",
    "    \n",
    "    def reg_check(self,m):\n",
    "        \"\"\"\n",
    "        register check\n",
    "        \"\"\"\n",
    "        if hasattr(m.forward,\"armed\"):\n",
    "            if m.forward.armed:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def set_metric(self, ttype):\n",
    "        assert ttype in self.legit_ttypes, f\"ttype has to be one of {str(self.ttypes)}\"\n",
    "        def deco(f):\n",
    "            setattr(self,f\"record_{ttype}_core\",self.record_core(f))\n",
    "            return f\n",
    "        return deco\n",
    "    \n",
    "    def add_record(f):\n",
    "        def _inner(self, f_name): return partial(f, self, f_name)\n",
    "        return _inner\n",
    "    \n",
    "    @add_record\n",
    "    def record_core(self, f_name, tensor, extra_data):\n",
    "        \"\"\"\n",
    "        extra_data: dict\n",
    "        \"\"\"\n",
    "        dict_= f_name(tensor)\n",
    "        dict_.update(extra_data)\n",
    "        self.t(dict_)\n",
    "        return dict_\n",
    "    \n",
    "    def record_input(self,mt):\n",
    "        \"\"\"\n",
    "        Record the input tensors of the moduleTrack\n",
    "        \"\"\"\n",
    "        for k,tensor in mt.input_dt.items():\n",
    "            extra_data= {\"module\":mt.name,\"ts\":self.t.ts,\"ttype\":\"input\",\"tname\":k}\n",
    "            if self.record_extra: self.add_extra_info(extra_data)\n",
    "            self.record_in_core(tensor, extra_data)\n",
    "            \n",
    "    def record_output(self,mt):\n",
    "        \"\"\"\n",
    "        Record the output tensors of the moduleTrack\n",
    "        \"\"\"\n",
    "        for i in range(len(mt.output_dt)):\n",
    "            tensor = mt.output_dt[i]\n",
    "            extra_data = {\"module\":mt.name,\"ts\":self.t.ts,\"ttype\":\"output\",\"tname\":f\"output_{i}\"}\n",
    "            if self.record_extra:self.add_extra_info(extra_data)\n",
    "            self.record_out_core(tensor,extra_data)\n",
    "            \n",
    "    def record_weight(self,mt):\n",
    "        \"\"\"\n",
    "        Record the weights of the moduleTrack\n",
    "        \"\"\"\n",
    "        if mt.base_module:\n",
    "            i = 0\n",
    "            for p in mt.module.parameters():\n",
    "                extra_data={\"module\":mt.name,\"ts\":self.t.ts,\n",
    "                                            \"ttype\":\"weight\",\"tname\":f\"weight_{i}\"}\n",
    "                if self.record_extra: self.add_extra_info(extra_data)\n",
    "                self.record_weight_core(p.data, extra_data)\n",
    "                if p.requires_grad and (p.grad!= None):\n",
    "                    extra_data={\"module\":mt.name,\"ts\":self.t.ts,\n",
    "                                            \"ttype\":\"weight_grad\",\"tname\":f\"grad_{i}\"}\n",
    "                    if self.record_extra: self.add_extra_info(extra_data)\n",
    "                    self.record_weight_core(p.grad, extra_data)\n",
    "                i+=1\n",
    "                \n",
    "    def add_extra(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Record the epoch # and batch #, in order to track the change of parameters over training process.\n",
    "        After the model is armed, when users put model in training loop, have option to set it up. \n",
    "        \"\"\"\n",
    "        self.record_extra = True\n",
    "        self.extra_info={}\n",
    "        for key, value in kwargs.items():\n",
    "            self.extra_info.update({f'{key}': value})\n",
    "        \n",
    "    def add_extra_info(self,extra_data):\n",
    "        extra_data.update(self.extra_info)\n",
    "    \n",
    "    def after_train(self):\n",
    "        \"\"\"\n",
    "        reset record batch after training\n",
    "        \"\"\"\n",
    "        if self.record_extra: \n",
    "            self.record_extra=False\n",
    "            self.extra_info = None\n",
    "        \n",
    "        \n",
    "    def module_register(self,name,m):\n",
    "        if self.reg_check(m) == False: return m.forward\n",
    "        f = m.forward\n",
    "        mt = self.modules[name]\n",
    "        vs = f.__code__.co_varnames\n",
    "        mt.vars = vs[1:]\n",
    "        if self.verbose: \n",
    "            color.cyan | f\"[BUILD FORWARD][{name}]{self.ts}\"\n",
    "        def new_forward(*args,**kwargs):\n",
    "            mt.input_dt = dict(zip(mt.vars[:len(args)],args))\n",
    "            mt.input_dt.update(kwargs)\n",
    "            \n",
    "            self.record_input(mt)\n",
    "            self.current_mt = mt\n",
    "            if mt.root_module: self.mt_log=[]\n",
    "            self.mt_log.append(f\"enter {mt.name}\")\n",
    "            \n",
    "            # ------execution of the function------\n",
    "            outputs = f(*args,**kwargs)\n",
    "            self.record_weight(mt)\n",
    "            # ------execution of the function------\n",
    "            \n",
    "            self.mt_log.append(f\"exit {mt.name}\")\n",
    "            \n",
    "            if type(outputs) in [list,tuple]:\n",
    "                mt.output_dt = [outputs]\n",
    "            else:\n",
    "                mt.output_dt = [outputs,]\n",
    "            self.record_output(mt)\n",
    "            \n",
    "            if mt.root_module:\n",
    "                self.t.refresh() # start a new \"latest\" file\n",
    "            \n",
    "            return outputs\n",
    "        \n",
    "        setattr(new_forward,\"armed\",True)\n",
    "        setattr(new_forward,\"former\",f)\n",
    "        \n",
    "        def disarm(this):\n",
    "            \"\"\"\n",
    "            Remove the trackers placed by torchember\n",
    "            run model.disarm()\n",
    "            \"\"\"\n",
    "            self.disarm()\n",
    "            return this\n",
    "        setattr(mt.module, \"disarm\",MethodType(disarm,mt.module))\n",
    "        return new_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking a model !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start tracking a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mstart analyzing model\u001b[0m\n",
      "\u001b[93m[ARMING][START]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).0(Conv2d)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).1(ReLU)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).2(MaxPool2d)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).3(Conv2d)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).4(ReLU)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).5(MaxPool2d)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).6(Conv2d)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).7(ReLU)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).8(Conv2d)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).9(ReLU)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).10(Conv2d)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).11(ReLU)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).12(MaxPool2d)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).avgpool(AdaptiveAvgPool2d)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).0(Dropout)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).1(Linear)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).2(ReLU)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).3(Dropout)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).4(Linear)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).5(ReLU)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).6(Linear)]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[93m[ARMING][SUCCESS]2020-03-07 10:37:37\u001b[0m\n",
      "\u001b[92m[INFO][20200307_103737]Creating meta data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "te = torchEmber(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the trackers we placed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[DISARM][model(AlexNet)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).0(Conv2d)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).1(ReLU)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).2(MaxPool2d)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).3(Conv2d)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).4(ReLU)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).5(MaxPool2d)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).6(Conv2d)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).7(ReLU)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).8(Conv2d)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).9(ReLU)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).10(Conv2d)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).11(ReLU)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).12(MaxPool2d)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).avgpool(AdaptiveAvgPool2d)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).0(Dropout)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).1(Linear)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).2(ReLU)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).3(Dropout)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).4(Linear)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).5(ReLU)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).6(Linear)]2020-03-07 10:37:39\u001b[0m\n",
      "\u001b[94m[DISARM][DONE]2020-03-07 10:37:39\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = model.disarm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[DISARM][model(AlexNet)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).0(Conv2d)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).1(ReLU)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).2(MaxPool2d)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).3(Conv2d)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).4(ReLU)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).5(MaxPool2d)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).6(Conv2d)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).7(ReLU)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).8(Conv2d)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).9(ReLU)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).10(Conv2d)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).11(ReLU)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).12(MaxPool2d)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).avgpool(AdaptiveAvgPool2d)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).0(Dropout)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).1(Linear)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).2(ReLU)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).3(Dropout)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).4(Linear)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).5(ReLU)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).6(Linear)]2020-03-07 10:37:40\u001b[0m\n",
      "\u001b[94m[DISARM][DONE]2020-03-07 10:37:40\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "te.disarm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, refresh the tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m[DISARM][model(AlexNet)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).0(Conv2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).1(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).2(MaxPool2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).3(Conv2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).4(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).5(MaxPool2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).6(Conv2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).7(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).8(Conv2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).9(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).10(Conv2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).11(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).features(Sequential).12(MaxPool2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).avgpool(AdaptiveAvgPool2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).0(Dropout)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).1(Linear)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).2(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).3(Dropout)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).4(Linear)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).5(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][model(AlexNet).classifier(Sequential).6(Linear)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[94m[DISARM][DONE]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[93m[ARMING][START]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).0(Conv2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).1(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).2(MaxPool2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).3(Conv2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).4(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).5(MaxPool2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).6(Conv2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).7(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).8(Conv2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).9(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).10(Conv2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).11(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).features(Sequential).12(MaxPool2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).avgpool(AdaptiveAvgPool2d)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).0(Dropout)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).1(Linear)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).2(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).3(Dropout)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).4(Linear)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).5(ReLU)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[96m[BUILD FORWARD][model(AlexNet).classifier(Sequential).6(Linear)]2020-03-07 10:37:41\u001b[0m\n",
      "\u001b[93m[ARMING][SUCCESS]2020-03-07 10:37:41\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "te.rearm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run forward pass for 3 iterations, nothing strange happend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "te.mark(phase=\"train\")\n",
    "for epoch in range(2):\n",
    "    te.mark(epoch=epoch)\n",
    "    for batch in range(3):\n",
    "        te.add_extra(n_batch=batch)\n",
    "        model(samp)\n",
    "te.mark(phase=\"valid\")\n",
    "for epoch in range(2):\n",
    "    te.mark(epoch=epoch)\n",
    "    for batch in range(2):\n",
    "        te.add_extra(n_batch=batch)\n",
    "        model(samp)\n",
    "te.after_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2248\r\n",
      "-rw-r--r--  1 salvor  staff   59804 Mar  3 23:51 init-00_phase-train_epoch-0.log\r\n",
      "-rw-r--r--  1 salvor  staff   59832 Mar  3 23:51 init-00_phase-train_epoch-1.log\r\n",
      "-rw-r--r--  1 salvor  staff   39868 Mar  3 23:51 init-00_phase-valid_epoch-0.log\r\n",
      "-rw-r--r--  1 salvor  staff  942405 Mar  3 23:52 init-00_phase-valid_epoch-1.log\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ~/.torchember/log/AlexNet_20200303_235054"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check snowballing tensor stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.t.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's start record weight grad data, once we use backward(), we'll soon have grad data kick in when next forward pass is called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track weight gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    model(samp).mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see here, for conv layer, \n",
    "* grad_0 is for the 1st weight grad tensor(weight), \n",
    "* grad_1 is for the 2nd(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module tree json\n",
    "This file will be stored at ```$HOME/.torchember/data/structure_<modelname>_<date>_<time>.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te.mod_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te.mt_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check latest tensor stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te.t.latest_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redifine what you want to record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the default statistic function, you can keep track shape, mean, std, max,min of a tensor.\n",
    "\n",
    "The afore-mentioned tensor could mean all of the following\n",
    "* module input tensors\n",
    "* module output tensors\n",
    "* module weight\n",
    "* gradient of module weight\n",
    "\n",
    "If you have more interesting metrics to follow, you can redifine the statistic tracking function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redifine the weight tensor/ weight grad tensor  statitic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@te.set_metric(\"weight\")\n",
    "def weight_stats(tensor):\n",
    "    return {\"num\":tensor.numel(),\"row_max\":list(row.max().item() for row in tensor)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redifine the input or output statitic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@te.set_metric(\"in\")\n",
    "def input_stats(tensor):\n",
    "    return {\"num\":tensor.numel(),\"row_min\":list(row.min().item() for row in tensor)}\n",
    "\n",
    "@te.set_metric(\"out\")\n",
    "def output_stats(tensor):\n",
    "    return {\"num\":tensor.numel(),\"row_min\":list(row.min().item() for row in tensor)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give 1 forward pass again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latest stats changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>row_min</th>\n",
       "      <th>module</th>\n",
       "      <th>ts</th>\n",
       "      <th>ttype</th>\n",
       "      <th>tname</th>\n",
       "      <th>row_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301056</td>\n",
       "      <td>[-1.9999991655349731, -1.9999991655349731]</td>\n",
       "      <td>model(AlexNet)</td>\n",
       "      <td>2020-03-05 23:10:22</td>\n",
       "      <td>input</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301056</td>\n",
       "      <td>[-1.9999991655349731, -1.9999991655349731]</td>\n",
       "      <td>model(AlexNet).features(Sequential)</td>\n",
       "      <td>2020-03-05 23:10:22</td>\n",
       "      <td>input</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301056</td>\n",
       "      <td>[-1.9999991655349731, -1.9999991655349731]</td>\n",
       "      <td>model(AlexNet).features(Sequential).0(Conv2d)</td>\n",
       "      <td>2020-03-05 23:10:22</td>\n",
       "      <td>input</td>\n",
       "      <td>input</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>model(AlexNet).features(Sequential).0(Conv2d)</td>\n",
       "      <td>2020-03-05 23:10:22</td>\n",
       "      <td>weight</td>\n",
       "      <td>weight_0</td>\n",
       "      <td>[0.0520191565155983, 0.05243277549743652, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>model(AlexNet).features(Sequential).0(Conv2d)</td>\n",
       "      <td>2020-03-05 23:10:22</td>\n",
       "      <td>weight_grad</td>\n",
       "      <td>grad_0</td>\n",
       "      <td>[3.522511906339787e-05, 1.3242663044366054e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>model(AlexNet).classifier(Sequential).6(Linear)</td>\n",
       "      <td>2020-03-05 23:10:23</td>\n",
       "      <td>weight</td>\n",
       "      <td>weight_1</td>\n",
       "      <td>[-0.004558052867650986, 0.014331953600049019, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>model(AlexNet).classifier(Sequential).6(Linear)</td>\n",
       "      <td>2020-03-05 23:10:23</td>\n",
       "      <td>weight_grad</td>\n",
       "      <td>grad_1</td>\n",
       "      <td>[0.003000000026077032, 0.003000000026077032, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2000</td>\n",
       "      <td>[-0.03184821456670761, -0.0329386442899704]</td>\n",
       "      <td>model(AlexNet).classifier(Sequential).6(Linear)</td>\n",
       "      <td>2020-03-05 23:10:23</td>\n",
       "      <td>output</td>\n",
       "      <td>output_0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2000</td>\n",
       "      <td>[-0.03184821456670761, -0.0329386442899704]</td>\n",
       "      <td>model(AlexNet).classifier(Sequential)</td>\n",
       "      <td>2020-03-05 23:10:23</td>\n",
       "      <td>output</td>\n",
       "      <td>output_0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2000</td>\n",
       "      <td>[-0.03184821456670761, -0.0329386442899704]</td>\n",
       "      <td>model(AlexNet)</td>\n",
       "      <td>2020-03-05 23:10:23</td>\n",
       "      <td>output</td>\n",
       "      <td>output_0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num                                      row_min  \\\n",
       "0   301056   [-1.9999991655349731, -1.9999991655349731]   \n",
       "1   301056   [-1.9999991655349731, -1.9999991655349731]   \n",
       "2   301056   [-1.9999991655349731, -1.9999991655349731]   \n",
       "3    23232                                          NaN   \n",
       "4    23232                                          NaN   \n",
       "..     ...                                          ...   \n",
       "75    1000                                          NaN   \n",
       "76    1000                                          NaN   \n",
       "77    2000  [-0.03184821456670761, -0.0329386442899704]   \n",
       "78    2000  [-0.03184821456670761, -0.0329386442899704]   \n",
       "79    2000  [-0.03184821456670761, -0.0329386442899704]   \n",
       "\n",
       "                                             module                   ts  \\\n",
       "0                                    model(AlexNet)  2020-03-05 23:10:22   \n",
       "1               model(AlexNet).features(Sequential)  2020-03-05 23:10:22   \n",
       "2     model(AlexNet).features(Sequential).0(Conv2d)  2020-03-05 23:10:22   \n",
       "3     model(AlexNet).features(Sequential).0(Conv2d)  2020-03-05 23:10:22   \n",
       "4     model(AlexNet).features(Sequential).0(Conv2d)  2020-03-05 23:10:22   \n",
       "..                                              ...                  ...   \n",
       "75  model(AlexNet).classifier(Sequential).6(Linear)  2020-03-05 23:10:23   \n",
       "76  model(AlexNet).classifier(Sequential).6(Linear)  2020-03-05 23:10:23   \n",
       "77  model(AlexNet).classifier(Sequential).6(Linear)  2020-03-05 23:10:23   \n",
       "78            model(AlexNet).classifier(Sequential)  2020-03-05 23:10:23   \n",
       "79                                   model(AlexNet)  2020-03-05 23:10:23   \n",
       "\n",
       "          ttype     tname                                            row_max  \n",
       "0         input         x                                                NaN  \n",
       "1         input     input                                                NaN  \n",
       "2         input     input                                                NaN  \n",
       "3        weight  weight_0  [0.0520191565155983, 0.05243277549743652, 0.05...  \n",
       "4   weight_grad    grad_0  [3.522511906339787e-05, 1.3242663044366054e-05...  \n",
       "..          ...       ...                                                ...  \n",
       "75       weight  weight_1  [-0.004558052867650986, 0.014331953600049019, ...  \n",
       "76  weight_grad    grad_1  [0.003000000026077032, 0.003000000026077032, 0...  \n",
       "77       output  output_0                                                NaN  \n",
       "78       output  output_0                                                NaN  \n",
       "79       output  output_0                                                NaN  \n",
       "\n",
       "[80 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.t.latest_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placing tracker on variables\n",
    "To be experimented here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = list(model.features.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import BuiltinMethodType,BuiltinFunctionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1 = torch.rand(5,6)\n",
    "x2 = torch.rand(5,6)\n",
    "x3 = x1*6+x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1462, 0.6524, 0.6635, 0.0931, 0.8485, 0.3402],\n",
       "        [0.6705, 0.0846, 0.6348, 0.3046, 0.7542, 0.6418],\n",
       "        [0.6934, 0.4078, 0.9792, 0.1871, 0.7833, 0.6145],\n",
       "        [0.6606, 0.6178, 0.2674, 0.4398, 0.4242, 0.2114],\n",
       "        [0.9054, 0.9068, 0.6374, 0.8210, 0.7212, 0.4652]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.abs_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TorchTensorEmber(x):\n",
    "    class TensorEmber(x.__class__):\n",
    "        def __init__(self,x):\n",
    "            self.host_ = x\n",
    "            attrs = dir(x)\n",
    "            for attr in attrs:\n",
    "                self.super_attr(attr)\n",
    "            \n",
    "        def super_attr(self,attr):\n",
    "            if inspect.isbuiltin(getattr(self.host_,attr))==False: return \n",
    "            def func(self,*args,**kwargs):\n",
    "                print(attr)\n",
    "                return getattr(super(),attr)(*args,**kwargs)\n",
    "            func.__name__ = attr\n",
    "            setattr(self,attr, MethodType(func,self))\n",
    "            return func\n",
    "            \n",
    "    return TensorEmber(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = TorchTensorEmber(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0196, 1.1548, 1.1521, 0.1822, 1.7265, 0.4464],\n",
       "        [1.2865, 0.4544, 0.9891, 0.8650, 1.1334, 1.2300],\n",
       "        [1.3343, 0.8323, 1.9395, 1.1801, 1.5499, 0.7846],\n",
       "        [1.1385, 1.2144, 0.6191, 0.6455, 0.9545, 0.8413],\n",
       "        [1.3088, 1.7986, 1.2820, 1.6781, 1.5974, 0.9433]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.add(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0196, 1.1548, 1.1521, 0.1822, 1.7265, 0.4464],\n",
       "        [1.2865, 0.4544, 0.9891, 0.8650, 1.1334, 1.2300],\n",
       "        [1.3343, 0.8323, 1.9395, 1.1801, 1.5499, 0.7846],\n",
       "        [1.1385, 1.2144, 0.6191, 0.6455, 0.9545, 0.8413],\n",
       "        [1.3088, 1.7986, 1.2820, 1.6781, 1.5974, 0.9433]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2+x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placing tracker on optimizer\n",
    "To be experimented here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
