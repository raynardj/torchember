# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/20_why_hat.ipynb (unless otherwise specified).

__all__ = ['md5hash', 'ModelInput', 'InputEmb', 'InputOneHot', 'InputConti', 'YEncoder', 'YOneHot', 'YConti',
           'RichColumn', 'RichDF', 'TabularModel', 'TabularNN']

# Cell
import pandas as pd
import numpy as np
from pathlib import Path
import os
import json
from .core import color
from .helper import tracker
os.environ['KMP_DUPLICATE_LIB_OK']='True'

# Cell
from hashlib import md5
from datetime import datetime
from torch import nn
import torch
import numpy as np
def md5hash(x):
    return md5(x.encode()).hexdigest()

# Cell
class ModelInput(nn.Module):
    def __init__(self,rich_col):
        super().__init__()
        self.rich_col = rich_col
        rich_col.input_module =self

class InputEmb(ModelInput):
    def __init__(self,rich_col):
        super().__init__(rich_col)
        self.emb = nn.Embedding(len(rich_col.top_freq)+1,rich_col.hidden_size)

    def forward(self,x):
        return self.emb(x)

class InputOneHot(ModelInput):
    def __init__(self,rich_col):
        super().__init__(rich_col)
        self.eye = torch.eye(len(self.rich_col))

    def forward(self,x):
        return self.eye[x]

class InputConti(ModelInput):
    def __init__(self,rich_col):
        super().__init__(rich_col)
        rich_col.mean = rich_col.col.mean()
        rich_col.std = rich_col.col.std()
        self.bn=nn.BatchNorm1d(1)
        self.tanh = nn.Tanh()

    def forward(self,x):
        x = self.tanh(self.bn(x))
        return x.detach()


# Cell
class YEncoder:
    """
    Encode the why into the required shape
    input of the __call__, numpy array
    """
    def __init__(self,rich_col):
        super().__init__()
        self.rich_col = rich_col
        assert rich_col.is_y,f"{rich_col.name} isn't a y column set"
        rich_col.y_encoder = self

    def __call__(self,x):
        raise NotImplementedError("Defind __call__ of YEncoder first")

class YOneHot(YEncoder):
    def __init__(self, rich_col):
        super().__init__(rich_col)
        self.eye = np.eye(len(rich_col)).astype(np.int)

    def __call__(self, x):
        return self.eye[x]

class YConti(YEncoder):
    def __init__(self, rich_col):
        super().__init__(rich_col)
        self.mean = rich_col.col.mean()
        self.std = rich_col.col.std()

    def __call__(self,x):
        return np.clip((x-self.mean)/self.std,-2,2)

# Cell
class RichColumn(object):
    """
    A pandas series manager
    """
    def __init__(self,column, is_y = False,min_occur = 5, is_emb = True,hidden_size=20):
        self.col = column
        self.col.rc = self
        self.name = self.col.name
        self.min_occur = min_occur
        self.hidden_size = hidden_size
        self.is_emb =  is_emb
        self.is_y = is_y
        self.use = True
        self.is_conti = True
        self.defined = False

    def kill(self):
        """
        set column to kill mode, that it would not be involved in the learning
        """
        self.defined = True
        self.use = False

    def conti(self):
        """
        set column to contineous data
        """
        self.defined = True
        self.is_conti = True

    def disc(self):
        """
        set column to discrete data
        """
        self.defined = True
        self.is_conti = False

    def is_number(self):
        """
        Is this column's data type in any form of number
        """
        return self.col.dtype in (int,float,
                              np.float16,np.float32,np.float64,np.float64,
                              np.int0,np.int8,np.int16,np.int32,np.int64)

    def __bool__(self):
        """
        is this column going to join the learning
        """
        return self.use

    def __len__(self):
        """
        width of column when entering the model, or used as target
        """
        if self.is_conti:
            return 1
        else:
            if self.is_emb and (self.is_y==False):
                return self.hidden_size
            else:
                width = len(self.top_freq)+1
                width =1 if width==2 else width
                return width

    def __repr__(self,):
        return f"<Rich Column:{self.name}>"

    def top_freq_(self):
        freq = self.freq()
        self.top_freq = freq[freq[self.name]>=self.min_occur].reset_index()
        self.tokens = dict((v,k+1) for k,v in enumerate(self.top_freq["index"]))
        self.token_arr = np.array(["<mtk>",]+list(self.top_freq["index"]))
        return self.top_freq

    def freq(self):
        return pd.DataFrame(data=self.col.value_counts())

    @property
    def conf_dict(self):
        return dict((i,getattr(self,i)) for i in ["name","defined","is_conti","is_y","is_emb","use"])

    def set_conf(self,conf_dict):
        for k,v in conf_dict.items():
            setattr(self,k,v)
        return self

    def encode(self,x):
        if self.is_conti:
            return x if x else self.mean
        else:
            try:
                return self.tokens[x]
            except:
                return 0

    def decode(self,idx):
        return self.token_arr[idx]

    def build_learn(self):
        """
        prepare the column for learning
        """
        if self.is_y == False:
            if self.is_conti:
                self.mean = self.col.mean()
                InputConti(self)
            else:
                InputEmb(self)
        else:
            if self.is_conti:
                self.mean = self.col.mean()
                YConti(self)
            else:
                YOneHot(self)
        return self

# Cell
class RichDF(object):
    """
    A pandas dataframe manager
    """
    def __init__(self,df,fname=None):
        self.df = df
        self.columns = dict()
        if fname==None:
            fname=f"why_hat_{self.ts_str}"
        self.t = tracker("torchember",fname)
        self.t.data = self.t.log_path

        for colname in self.df:
            self.columns.update({colname:RichColumn(df[colname])})

    @property
    def ts_str(self):
        return datetime.now().strftime("%m%d_%H%M%S")

    @property
    def col_conf(self):
        return dict((k,{"use":v.use,"is_cont":v.is_conti}) for k,v in self.columns.items())

    def __getitem__(self,col_name):
        return self.columns[col_name]

    def kill(self,colname):
        """
        Not using this column
        """
        self.df[colname].rc.kill()

    def conti(self,colname):
        self.df[colname].rc.conti()

    def disc(self,colname):
        self.df[colname].rc.disc()

    def save_col(self,rcol):
        self.t[md5hash(rcol.name)]=rcol.conf_dict

    def set_col(self,rcol):
        if rcol.defined:
            print(f"{rcol.name} defined, use:{rcol.use}, contineus?:{rcol.is_conti}")
        print(color.bold("="*30))
        print(color.cyan(rcol.name))
        print(color.red(f"number? {rcol.is_number()}"))
        print(rcol.top_freq_().head(5))

        print(color.red("Is this a [C]ontineous, [D]iscrete or a column we do[N]'t need? default N"))
        x = input().lower()
        if x=="c":
            rcol.conti()
            print(color.blue(f"{rcol.name} set to contineous data"))
            self.save_col(rcol)
        elif x =="d":
            rcol.disc()
            print(color.blue(f"{rcol.name} set to discrite data"))
            self.save_col(rcol)
        elif (x =="") or (x=="n"):
            rcol.kill()
            print(color.blue(f"{rcol.name} will not be involved in learning"))
            self.save_col(rcol)
        else:
            print(color.yellow(f"option [{x}] not found, try Again?"))

    def save(self,colname):
        col=self.df[colname]
        self.t[md5hash(colname)] = col.rc.conf_dict

    def read(self,colname):
        col=self.df[colname]
        col.rc.set_conf(self.t[md5hash(colname)])
        if col.rc.is_conti:
            col.rc.top_freq_()

    def shuffle_df(self):
        self.df = self.df\
        .sample(frac=1.)\
        .reset_index().drop("index",axis=1)

    def tour(self):
        """
        Go through column 1 by 1 to decide the processing for its data
        """
        for colname in self.df:
            col = self.df[colname]
            current = self.t[md5hash(colname)]
            if current != None:
                col.rc.set_conf(current)
                if col.rc.is_conti==False:
                    col.rc.top_freq_()
            if col.rc.defined==False:
                self.set_col(col.rc)

    def set_y(self, *colnames):
        """
        set columns to y
        all the columns that use==True and is_y==False will be treated as x
        """
        for colname in colnames:
            rc = self.columns[colname]
            rc.is_y = True
            rc.use = True
            rc.is_emb = False
            self.save(colname)

    def set_x(self, *colnames):
        """
        set columns to x
        of course,every columns' default status is x,
        so you don't have to set this if you accidentally set x to y
        """
        for colname in colnames:
            rc = self.columns[colname]
            rc.use = True
            rc.is_y = False
            self.save(colname)

    @property
    def Xs(self):
        """
        Return the next x rich column
        """
        for col,rc in self.columns.items():
            if (rc.is_y) ==False and rc.use:
                yield rc

    @property
    def Ys(self):
        """
        Return the next y rich column
        """
        for col,rc in self.columns.items():
            if rc.is_y and rc.use:
                yield rc


# Cell
class TabularModel(nn.Module):
    def __init__(self,rdf):
        super().__init__()
        self.rdf=rdf
        self.inputs = nn.ModuleDict(modules = dict((x.name,x.input_module) for x in rdf.Xs))

        self.build_dial_x()
        self.build_dial_y()

        self.input_width = len(self.dial)
        self.target_width = len(self.dial_y)

        self.hidden_size = max(self.input_width,self.target_width,20)
        self.dnn = nn.Sequential(*[
            nn.Linear(self.input_width,self.hidden_size),
            nn.BatchNorm1d(self.hidden_size),
            nn.ReLU(),
            nn.Linear(self.hidden_size,self.target_width),
            nn.BatchNorm1d(self.target_width),
        ])

    def forward(self,Xs):
        """
        Xs dictionary of inputs
        """
        ipts = list(self.inputs[xcol.name](Xs[xcol.name]) for xcol in self.rdf.Xs)
        concat = torch.cat(ipts,dim=1)
        return self.dnn(concat)

    def build_dial_x(self):
        all_width = 0
        self.dial = dict()
        for x in self.rdf.Xs:
            for i in range(len(x)):
                self.dial.update({all_width:dict({"colname":x.name,
                                                  "rich_col":x,
                                                  "sub_idx":i,
                                                  "remark":f"input<{i}> of column {x.name}"})})
                all_width+=1
        return all_width

    def build_dial_y(self):
        all_width = 0
        self.dial_y = dict()
        for y in self.rdf.Ys:
            for i in range(len(y)):
                self.dial_y.update({all_width:dict({"colname":y.name,
                                                  "rich_col":y,
                                                  "sub_idx":i,
                                                  "remark":f"target<{i}> of column {y.name}"})})
                all_width+=1
        return all_width

class TabularNN:
    def __init__(self, rich_df,batch_size=128):
        self.rich_df = rich_df
        self.l = len(rich_df.df)
        self.batch_size = batch_size
        self.x = list(x.build_learn() for x in self.rich_df.Xs)
        self.y = list(y.build_learn() for y in self.rich_df.Ys)
        self.assert_xy()
        self.assert_y_consistency()
        self.reset_i()
        self.epoch = 0
        self.rich_df.shuffle_df()
        self.model = TabularModel(self.rich_df)

    def reset_i(self):
        """reset iterator"""
        self.s=0
        self.e=1

    def __repr__(self):
        return f">>TabularNN"

    def assert_xy(self):
        assert len(self.x)>0, "You have you set some X"
        assert len(self.y)>0, "You have you set some Y"

    def assert_y_consistency(self):
        conti_list = list(rc.is_conti for rc in self.rich_df.Ys)
        assert float(sum(conti_list))/len(conti_list) in [1.,0.],"Y has to be all discrete columns, or contineous columns"
        # decide loss function based on Y
        if conti_list[0]:
            self.crit = nn.MSELoss()
        else:
            self.crit = nn.BCEWithLogitsLoss()

    def build_model_nn(self):
        self.nn = TabularModel(self)

    def batch_df(self):
        start = self.batch_size*self.s
        end = self.batch_size*self.e
        if start>self.l:
            self.epoch+=1
            self.reset_i()
            start = self.batch_size*self.s
            end = self.batch_size*self.e
        yield self.rich_df.df[start:end]

    def batch_array(self):
        df_b = next(self.batch_df())
        x_data = dict()
        y_data = dict()

        for x in self.x:
            if x.is_conti:
                df_b[x.name]= df_b[x.name].fillna(x.mean)
            arr = df_b[x.name].apply(x.encode).values
            x_tensor = torch.FloatTensor(arr)[:,None] if x.is_conti else torch.LongTensor(arr)
            x_data.update({x.name:x_tensor})

        for y in self.y:
            arr = df_b[y.name].apply(y.encode).values
            y_tensor = torch.FloatTensor(arr) if y.is_conti else torch.LongTensor(arr)
            y_data.update({y.name:y_tensor[:,None]})
        yield x_data,y_data

    def batch_y_pred(self):
        x_data,y_data = next(self.batch_array())
        yield self.model(x_data)
